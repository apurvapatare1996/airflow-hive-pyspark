# airflow-hive-pyspark
1. import parquet file through airflow using spark and insert into hive ----------------------------------------------------------------- 2. Read from hive and dump as csv ----------------------------------------------------------------- 3. Read from hive create condensed files using spark giving details of - how many females - how many males - avg salary of males - avg salary females - avg salary of organization - max salary of male - max salary of female - max salary of organization save as json ----------------------------------------------------------------- 4. convert json to parquet ----------------------------------------------------------------- 5. Github Create GitHub account. Configure machine with Git and ssh keys. From the master create a branch called release/0.0.1 Commit and push code to this branch. Verify whether the code has reached GitHub repository or not. Run various commands
